{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1e750f-cd10-4a3a-9657-655f08ac909c",
   "metadata": {},
   "source": [
    "### Looking at subset of activations with DeepScan\n",
    "\n",
    "This notebook shows the code steps to:\n",
    "\n",
    "1. Select hyperparameters to run deepscan.\n",
    "2. Load $H_0$ and $H_1$ activations.\n",
    "3. Extract activations across several layers.\n",
    "4. Run DeepScan and save output files and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e616d3a-bf34-4cd4-8ae9-bd24cb4f1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepscan.util.sampler import Sampler\n",
    "from deepscan.util.pvalranges_calculator import PvalueCalculator\n",
    "from deepscan.util.utils import scan_write_metrics, customsort\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcd42b3-42c1-4bbc-bb01-e3060819c04a",
   "metadata": {},
   "source": [
    "The hyperparameters defined below are:\n",
    "1. Type of run, `individual` looks at one statement at a time and yields the activations that make that sample the most divergent. `group` yields the subset of statements that are the most divergent with a fixed subset of activations.\n",
    "2. Scoring function: In this case, `hc` stands for [Higher-Criticism test](https://arxiv.org/pdf/math/0410072). DeepScan has implemented several scoring functions. ' hc tends to yield smaller subsets with very extreme p-value ranges, as this would produce large values in the numerator and smaller ones in the denominator compared to `bj`.\n",
    "3. Proportions of samples during evaluation time are defined in `clean_ssize` and `anom_ssize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1d2da4-82d6-43f8-9623-0991150b382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_NEG = \"./data/activations/llama3_negative_31_anti-immigration.npy\"\n",
    "PATH_POS = \"./data/activations/llama3_positive_31_anti-immigration.npy\"\n",
    "typerun = \"group\"\n",
    "scoring = \"hc\"\n",
    "model = \"Meta-Llama-3-8B-Instruct\"\n",
    "dataset = \"anti-immigration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c93720-e720-451e-b524-5c3664631ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 4096) (300, 4096) (50, 4096)\n"
     ]
    }
   ],
   "source": [
    "size = 50\n",
    "bg = np.load(PATH_NEG, allow_pickle=True)\n",
    "abnormal = np.load(PATH_POS, allow_pickle=True)\n",
    "\n",
    "clean = bg[:size]\n",
    "bg = bg[size:]\n",
    "\n",
    "print(bg.shape, abnormal.shape, clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f522a00-946e-4ac9-a4ba-b2d2e9096353",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    \"group\": {\n",
    "        \"clean\": {\"clean_ssize\": 50, \"anom_ssize\": 0},\n",
    "        \"abnormal\": {\"clean_ssize\": 25, \"anom_ssize\": 25},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e323aa0-2bc3-45e7-92fa-576d5b7d544c",
   "metadata": {},
   "source": [
    "The steps to run DeepScan are:\n",
    "1. Create expectation for $H_0$ with `PvalueCalculator(bg)`.\n",
    "2. Obtain pvalues for samples in test set from both $H_0$ and $H_1$ `pvalcalculator.get_pvalue_ranges()`.\n",
    "3. Do a random sampling with the sizes defined in the hyper parameters  `Sampler.sample()`.\n",
    "4. and then call the scanning search, scoring and output saving with `scan_write_metrics()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eddb8f5-b679-4d57-9159-a5b64233dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run for key: clean\n",
      "Beginning Scanning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 37.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run for key: abnormal\n",
      "Beginning Scanning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 39.14it/s]\n"
     ]
    }
   ],
   "source": [
    "number_runs = 100\n",
    "\n",
    "for key in [\"clean\", \"abnormal\"]:\n",
    "    print(\"Run for key: {}\".format(key))\n",
    "    clean_ssize = runs[typerun][key][\"clean_ssize\"]\n",
    "    anom_ssize = runs[typerun][key][\"anom_ssize\"]\n",
    "\n",
    "    if (clean_ssize != 1 and typerun == \"group\") or (\n",
    "        clean_ssize == 1 and typerun == \"individual\"\n",
    "    ):\n",
    "        resultsfile = \"./output/clean_output_{}_{}.txt\".format(dataset, scoring)\n",
    "    if anom_ssize != 0:\n",
    "        resultsfile = \"./output/adv_output_{}_{}.txt\".format(dataset, scoring)\n",
    "\n",
    "    bg = customsort(bg, conditional=False)\n",
    "    pvalcalculator = PvalueCalculator(bg)\n",
    "\n",
    "    records_pvalue_ranges = pvalcalculator.get_pvalue_ranges(clean, pvaltest=\"1tail\")\n",
    "    anom_records_pvalue_ranges = pvalcalculator.get_pvalue_ranges(\n",
    "        abnormal, pvaltest=\"1tail\"\n",
    "    )\n",
    "\n",
    "    if anom_ssize == 1 and clean_ssize == 0:\n",
    "        run = anom_records_pvalue_ranges.shape[0]\n",
    "\n",
    "    elif clean_ssize == 1 and anom_ssize == 0:\n",
    "        run = records_pvalue_ranges.shape[0]\n",
    "\n",
    "    samples, _ = Sampler.sample(\n",
    "        records_pvalue_ranges,\n",
    "        anom_records_pvalue_ranges,\n",
    "        clean_ssize,\n",
    "        anom_ssize,\n",
    "        number_runs,\n",
    "        conditional=False,\n",
    "    )\n",
    "\n",
    "    pool = Pool(processes=5)\n",
    "    calls = []\n",
    "\n",
    "    for r_indx in range(number_runs):\n",
    "        pred_classes = None\n",
    "        run_sampled_indices = None\n",
    "        sampled_indices = None\n",
    "\n",
    "        calls.append(\n",
    "            pool.apply_async(\n",
    "                scan_write_metrics,\n",
    "                [\n",
    "                    samples[r_indx],\n",
    "                    pred_classes,\n",
    "                    clean_ssize,\n",
    "                    anom_ssize,\n",
    "                    resultsfile,\n",
    "                    1,\n",
    "                    False,\n",
    "                    None,\n",
    "                    scoring,\n",
    "                    -1,\n",
    "                    run_sampled_indices,\n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(\"Beginning Scanning...\")\n",
    "    for sample in tqdm(calls):\n",
    "        sample.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac503d8c-5c9b-4643-b4ab-1953511a20c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Meta-Llama-3-8B-Instruct - anti-immigration 0.802633755838154 0.06394636294421967\n",
      "Recall for Meta-Llama-3-8B-Instruct - anti-immigration 0.8488888888888889 0.1213467266075249\n"
     ]
    }
   ],
   "source": [
    "from utils.utils_nodes import get_anom_nodes\n",
    "\n",
    "PATH_OUTPUT_ABN = \"output/adv_output_{}_{}.txt\".format(dataset, scoring)\n",
    "PATH_OUTPUT_CLN = \"output/clean_output_{}_{}.txt\".format(dataset, scoring)\n",
    "\n",
    "_, _, precision, recall, _ = get_anom_nodes(PATH_OUTPUT_ABN)\n",
    "print(\n",
    "    \"Precision for {} - {}\".format(model, dataset),\n",
    "    np.array(precision).mean(),\n",
    "    np.array(precision).std(),\n",
    ")\n",
    "print(\n",
    "    \"Recall for {} - {}\".format(model, dataset),\n",
    "    np.array(recall).mean(),\n",
    "    np.array(recall).std(),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
